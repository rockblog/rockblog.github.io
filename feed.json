{
    "version": "https://jsonfeed.org/version/1.1",
    "title": "Rockblog",
    "description": "Thought and work on the redrock postgres database",
    "home_page_url" : "http://blog.rockdata.net/",
    "feed_url" : "http://blog.rockdata.net/feed.json",
    "authors" : [
        {
            "name" : "John Doe"
        }
    ],
    "items" : [
        {
            "title" : "Getting Started",
            "date_published" : "2020-07-15T20:00:00+02:00",
            "date_modified" : "2022-05-24T09:25:10+08:00",
            "id" : "http://blog.rockdata.net/posts/usage/getting-started/",
            "url" : "http://blog.rockdata.net/posts/usage/getting-started/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\n\n\n  \u003cdiv class=\"gblog-toc gblog-toc__level--3\"\u003e\n    \u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#installation\"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#architectural-fundamentals\"\u003eArchitectural Fundamentals\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#accessing-database\"\u003eAccessing Database\u003c/a\u003e\u003c/li\u003e\n        \u003cli\u003e\u003ca href=\"#whats-next\"\u003eWhats next?\u003c/a\u003e\u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e\n    \u003chr /\u003e\n  \u003c/div\u003e\n\n\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"installation\"\u003e\n        Installation\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/getting-started/#installation\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Installation\" href=\"#installation\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eBefore you can use PostgreSQL you need to install it, of course. It is possible that PostgreSQL is already installed at your site, either because it was included in your operating system distribution or because the system administrator already installed it. If that is the case, you should obtain information from the operating system documentation or your system administrator about how to access PostgreSQL.\u003c/p\u003e\n\u003cp\u003eIf you are not sure whether PostgreSQL is already available or whether you can use it for your experimentation then you can install it yourself. Doing so is not hard and it can be a good exercise. PostgreSQL can be installed by any unprivileged user; no superuser (root) access is required.\u003c/p\u003e\n\u003cp\u003eIf you are installing PostgreSQL yourself, then refer to \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/14/installation.html\"\n  \n\u003eChapter 17\u003c/a\u003e for instructions on installation, and return to this guide when the installation is complete. Be sure to follow closely the section about setting up the appropriate environment variables.\u003c/p\u003e\n\u003cp\u003eIf your site administrator has not set things up in the default way, you might have some more work to do. For example, if the database server machine is a remote machine, you will need to set the \u003ccode\u003ePGHOST\u003c/code\u003e environment variable to the name of the database server machine. The environment variable \u003ccode\u003ePGPORT\u003c/code\u003e might also have to be set. The bottom line is this: if you try to start an application program and it complains that it cannot connect to the database, you should consult your site administrator or, if that is you, the documentation to make sure that your environment is properly set up. If you did not understand the preceding paragraph then read the next section.\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"architectural-fundamentals\"\u003e\n        Architectural Fundamentals\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/getting-started/#architectural-fundamentals\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Architectural Fundamentals\" href=\"#architectural-fundamentals\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eBefore we proceed, you should understand the basic PostgreSQL system architecture. Understanding how the parts of PostgreSQL interact will make this chapter somewhat clearer.\u003c/p\u003e\n\u003cp\u003eIn database jargon, PostgreSQL uses a client/server model. A PostgreSQL session consists of the following cooperating processes (programs):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA server process, which manages the database files, accepts connections to the database from client applications, and performs database actions on behalf of the clients. The database server program is called \u003ccode\u003epostgres\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eThe user\u0026rsquo;s client (frontend) application that wants to perform database operations. Client applications can be very diverse in nature: a client could be a text-oriented tool, a graphical application, a web server that accesses the database to display web pages, or a specialized database maintenance tool. Some client applications are supplied with the PostgreSQL distribution; most are developed by users.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAs is typical of client/server applications, the client and the server can be on different hosts. In that case they communicate over a TCP/IP network connection. You should keep this in mind, because the files that can be accessed on a client machine might not be accessible (or might only be accessible using a different file name) on the database server machine.\u003c/p\u003e\n\u003cp\u003eThe PostgreSQL server can handle multiple concurrent connections from clients. To achieve this it starts (“forks”) a new process for each connection. From that point on, the client and the new server process communicate without intervention by the original \u003ccode\u003epostgres\u003c/code\u003e process. Thus, the supervisor server process is always running, waiting for client connections, whereas client and associated server processes come and go. (All of this is of course invisible to the user. We only mention it here for completeness.)\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"accessing-database\"\u003e\n        Accessing Database\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/getting-started/#accessing-database\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Accessing Database\" href=\"#accessing-database\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eOnce you have created a database, you can access it by:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRunning the PostgreSQL interactive terminal program, called \u003cem\u003epsql\u003c/em\u003e, which allows you to interactively enter, edit, and execute SQL commands.\u003c/li\u003e\n\u003cli\u003eUsing an existing graphical frontend tool like pgAdmin or an office suite with ODBC or JDBC support to create and manipulate a database. These possibilities are not covered in this tutorial.\u003c/li\u003e\n\u003cli\u003eWriting a custom application, using one of the several available language bindings. These possibilities are discussed further in \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/client-interfaces.html\"\n  \n\u003ePart IV\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou probably want to start up \u003ccode\u003epsql\u003c/code\u003e to try the examples in this tutorial. It can be activated for the \u003ccode\u003epostgres\u003c/code\u003e database by typing the command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ psql postgres\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf you do not supply the database name then it will default to your user account name.\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003epsql\u003c/code\u003e, you will be greeted with the following message:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epsql (12.1)\nType \u0026#34;help\u0026#34; for help.\n\npostgres=\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe last line could also be:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epostgres=#\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThat would mean you are a database superuser, which is most likely the case if you installed the PostgreSQL instance yourself. Being a superuser means that you are not subject to access controls. For the purposes of this tutorial that is not important.\u003c/p\u003e\n\u003cp\u003eIf you encounter problems starting \u003ccode\u003epsql\u003c/code\u003e then go back to the previous section. The diagnostics of \u003ccode\u003ecreatedb\u003c/code\u003e and \u003ccode\u003epsql\u003c/code\u003e are similar, and if the former worked the latter should work as well.\u003c/p\u003e\n\u003cp\u003eThe last line printed out by \u003ccode\u003epsql\u003c/code\u003e is the prompt, and it indicates that \u003ccode\u003epsql\u003c/code\u003e is listening to you and that you can type SQL queries into a work space maintained by \u003ccode\u003epsql\u003c/code\u003e. Try out these commands:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epostgres=\u0026gt; SELECT version();\n                                         version\n------------------------------------------------------------------------------------------\n PostgreSQL 12.1 on x86_64-pc-linux-gnu, compiled by gcc (Debian 4.9.2-10) 4.9.2, 64-bit\n(1 row)\n\npostgres=\u0026gt; SELECT current_date;\n    date\n------------\n 2016-01-07\n(1 row)\n\npostgres=\u0026gt; SELECT 2 + 2;\n ?column?\n----------\n        4\n(1 row)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe \u003ccode\u003epsql\u003c/code\u003e program has a number of internal commands that are not SQL commands. They begin with the backslash character, “\u003ccode\u003e\\\u003c/code\u003e”. For example, you can get help on the syntax of various PostgreSQL SQL commands by typing:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epostgres=\u0026gt; \\h\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo get out of \u003ccode\u003epsql\u003c/code\u003e, type:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003epostgres=\u0026gt; \\q\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eand \u003ccode\u003epsql\u003c/code\u003e will quit and return you to your command shell. (For more internal commands, type \u003ccode\u003e\\?\u003c/code\u003e at the \u003ccode\u003epsql\u003c/code\u003e prompt.) The full capabilities of \u003ccode\u003epsql\u003c/code\u003e are documented in \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/app-psql.html\"\n  \n\u003epsql\u003c/a\u003e. In this tutorial we will not use these features explicitly, but you can use them yourself when it is helpful.\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"whats-next\"\u003e\n        Whats next?\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/getting-started/#whats-next\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Whats next?\" href=\"#whats-next\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eThere are a lot more things to discover. To get more information, please refer to \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/index.html\"\n  \n\u003ePostgreSQL Documentation\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Undo",
            "date_published" : "2020-06-13T00:06:00+02:00",
            "date_modified" : "2022-05-23T20:13:05+08:00",
            "id" : "http://blog.rockdata.net/posts/features/undo/",
            "url" : "http://blog.rockdata.net/posts/features/undo/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eRedrock Postgres maintains records of the actions of transactions, collectively known as undo data. Redrock Postgres uses undo to do the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRoll back an active transaction\u003c/li\u003e\n\u003cli\u003eRecover a terminated transaction\u003c/li\u003e\n\u003cli\u003eProvide read consistency\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRedrock Postgres stores undo data inside the database rather than in external logs. Undo data is stored in blocks that are updated just like data blocks, with changes to these blocks generating redo. In this way, Redrock Postgres can efficiently access undo data without needing to read external logs.\u003c/p\u003e\n\u003cp\u003eUndo data is stored in an independent tablespace. Redrock Postgres provides a fully automated mechanism, known as automatic undo management mode, for managing undos and space.\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch4 id=\"undos-and-transactions\"\u003e\n        Undos and Transactions\n    \u003c/h4\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/features/undo/#undos-and-transactions\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Undos and Transactions\" href=\"#undos-and-transactions\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eWhen a transaction starts, the database binds (assigns) the transaction to an undo segment, and therefore to a transaction table.\u003c/p\u003e\n\u003cp\u003eMultiple active transactions can write concurrently to the same undo or to different undos. For example, transactions T1 and T2 can both write to undo U1, or T1 can write to U1 while T2 writes to undo U2.\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch4 id=\"transaction-rollback\"\u003e\n        Transaction Rollback\n    \u003c/h4\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/features/undo/#transaction-rollback\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Transaction Rollback\" href=\"#transaction-rollback\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eWhen a \u003ccode\u003eROLLBACK\u003c/code\u003e statement is issued, the database uses undo records to roll back changes made to the database by the uncommitted transaction. During recovery, the database rolls back any uncommitted changes applied from the online redo log to the data files. Undo records provide read consistency by maintaining the before image of the data for users accessing data at the same time that another user is changing it.\u003c/p\u003e\n"
        },
        {
            "title" : "Criticism of relational database",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-27T20:54:03+08:00",
            "id" : "http://blog.rockdata.net/posts/software/database-criticism/",
            "url" : "http://blog.rockdata.net/posts/software/database-criticism/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#August_31_2020\"\n  \n\u003eThe Inner Workings of Oracle Development\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eOracle\u0026rsquo;s Steinar Gunderson posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://blog.sesse.net/blog/tech/2021-12-05-16-41_leaving_mysql.html\"\n  \n\u003eLeaving MySQL\u003c/a\u003e, and \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://news.ycombinator.com/item?id=29455852\"\n  \n\u003ediscussion at Hacker News\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eGitlab\u0026rsquo;s Kenny Johnston posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://about.gitlab.com/blog/2019/06/27/removing-mysql-support/\"\n  \n\u003eWhy we\u0026rsquo;re ending support for MySQL in 12.1\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUber\u0026rsquo;s Evan Klitzke posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.yumpu.com/en/document/view/53683323/migrating-uber-from-mysql-to-postgresql\"\n  \n\u003eMigrating Uber from MySQL to PostgreSQL\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eUber\u0026rsquo;s Evan Klitzke posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://eng.uber.com/postgres-to-mysql-migration/\"\n  \n\u003eWhy Uber Engineering Switched from Postgres to MySQL\u003c/a\u003e, and \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://news.ycombinator.com/item?id=26283348\"\n  \n\u003ediscussion at Hacker News\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eRick Branson posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://rbranson.medium.com/10-things-i-hate-about-postgresql-20dbab8c2791\"\n  \n\u003e10 Things I Hate About PostgreSQL\u003c/a\u003e, and \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://news.ycombinator.com/item?id=26709019\"\n  \n\u003ediscussion at Hacker News\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Migration from oracle to postgres",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-26T16:50:20+08:00",
            "id" : "http://blog.rockdata.net/posts/practice/oracle-to-postgres/",
            "url" : "http://blog.rockdata.net/posts/practice/oracle-to-postgres/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eThe toughest things happened in migration from oracle to postgres:\u003c/p\u003e\n\u003cp\u003eThe famous \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.modb.pro/db/82136\"\n  \n\u003eERROR: current transaction is aborted, commands ignored until end of transaction block\u003c/a\u003e, and some discussion in community\u0026rsquo;s pgsql-hackers group: \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/message-id/flat/0A3221C70F24FB45833433255569204D1F6A9286%40G01JPEXMBYT05\"\n  \n\u003eStatement-level rollback\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCNBC\u0026rsquo;s Eugene Kim posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.cnbc.com/2018/10/23/amazon-move-off-oracle-caused-prime-day-outage-in-warehouse.html\"\n  \n\u003eAmazon’s move off Oracle caused Prime Day outage in one of its biggest warehouses, internal report says\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAmazon\u0026rsquo;s Baji Shaik, Deepak Mahto, and Sudip Acharya posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://aws.amazon.com/blogs/database/convert-the-number-data-type-from-oracle-to-postgresql-part-1/\"\n  \n\u003eConvert the NUMBER data type from Oracle to PostgreSQL – Part 1\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAmazon\u0026rsquo;s Baji Shaik, Deepak Mahto, and Sudip Acharya posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://aws.amazon.com/blogs/database/convert-the-number-data-type-from-oracle-to-postgresql-part-2/\"\n  \n\u003eConvert the NUMBER data type from Oracle to PostgreSQL – Part 2\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eSome migration experience:\u003c/p\u003e\n\u003cp\u003eVenkata B Nagothi\u0026rsquo;s experience on migration: \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.pgconf.asia/JA/2016/wp-content/uploads/2016/12/pgConf-Asia-Japan.pdf\"\n  \n\u003eMigrations to PostgreSQL from Oracle\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Postgres things",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/software/postgres-things/",
            "url" : "http://blog.rockdata.net/posts/software/postgres-things/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#September_16_2020\"\n  \n\u003eWhy Not to Choose Postgres\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#July_8_2020\"\n  \n\u003ePostgres Marketing\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Some well-known database courses",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/software/database-courses/",
            "url" : "http://blog.rockdata.net/posts/software/database-courses/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eUC Berkeley published \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://cs186berkeley.net/\"\n  \n\u003eCS 186 (Spring 2022) Introduction to Database Systems\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCMU\u0026rsquo;s Andrew Crotty published \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://15445.courses.cs.cmu.edu/fall2021/\"\n  \n\u003eCMU 15-445 (FALL 2021) Intro to Database Systems\u003c/a\u003e, and related \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://15445.courses.cs.cmu.edu/fall2021/slides/\"\n  \n\u003eresources\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCMU\u0026rsquo;s Prof. Andy Pavlo published \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://15721.courses.cs.cmu.edu/spring2020/\"\n  \n\u003eCMU 15-721 (SPRING 2020) Advanced Database Systems\u003c/a\u003e, and related \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://15721.courses.cs.cmu.edu/spring2020/slides/\"\n  \n\u003eresources\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Trends of postgres's popularity",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/software/postgres-popularity/",
            "url" : "http://blog.rockdata.net/posts/software/postgres-popularity/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eAmazon\u0026rsquo;s Jeff Barr posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://aws.amazon.com/blogs/aws/migration-complete-amazons-consumer-business-just-turned-off-its-final-oracle-database/\"\n  \n\u003eMigration Complete – Amazon’s Consumer Business Just Turned off its Final Oracle Database\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2016.html#March_22_2016\"\n  \n\u003eOracle Attacks Postgres in Russia\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#September_30_2020\"\n  \n\u003eThree Postgres Adoption Groups in Enterprises\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2021.html#November_17_2021\"\n  \n\u003eEnterprise Postgres Growth in Japan\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePercona\u0026rsquo;s Matt Yonkovit posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://db-engines.com/en/blog_post/90\"\n  \n\u003eThe Inexorable Rise of PostgreSQL\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePercona\u0026rsquo;s Umair Shahid posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://db-engines.com/en/blog_post/92\"\n  \n\u003eDriving the Future of PostgreSQL Adoption\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "User centric product design",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-28T18:41:37+08:00",
            "id" : "http://blog.rockdata.net/posts/software/user-centric/",
            "url" : "http://blog.rockdata.net/posts/software/user-centric/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eAllen Zhang talks about product：\u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.huxiu.com/article/2142.html\"\n  \n\u003eProduct ideas\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eZhou Hongyi talks about product：\u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.huxiu.com/article/5957.html\"\n  \n\u003eMake products like you\u0026rsquo;re pregnant, and listen to criticism with a thick face\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eAmazon\u0026rsquo;s Constantin Gonzalez says \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://cdn0.scrvt.com/infopark23444378/16ee7c58ea6547e8/e1409f266854/Gonzalez_Innovating_on_Behalf_of_Customers-ilovepdf-compressed.pdf\"\n  \n\u003eInnovating on Behalf of Customers\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eNetgen\u0026rsquo;s Mario Blažek says \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://netgen.io/blog/the-most-overlooked-part-in-software-development-writing-project-documentation\"\n  \n\u003eThe most overlooked part in software development - writing project documentation\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCommand Prompt\u0026rsquo;s Joshua D. Drake states that PostgreSQL community should \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://commandprompt.com/blog/optimizing-documentation/\"\n  \n\u003eOptimizing the documentation\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "What dose Open Souce means to users and developers?",
            "date_published" : "2022-05-20T09:00:00+02:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/software/open-source/",
            "url" : "http://blog.rockdata.net/posts/software/open-source/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003esolid IT\u0026rsquo;s Matthias Gelbmann posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://db-engines.com/en/blog_post/86\"\n  \n\u003eOpen source database management systems are now more popular than commercial offerings\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#October_2_2020\"\n  \n\u003eThe Economics of Open Source Contributions\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#September_28_2020\"\n  \n\u003eCloud Vendor Monetization of Open Source\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#September_25_2020\"\n  \n\u003eCloud Vendors as a Barrier\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#September_23_2020\"\n  \n\u003eDevelopers in Front\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eEDB\u0026rsquo;s Bruce Momjian posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://momjian.us/main/blogs/pgblog/2020.html#August_26_2020\"\n  \n\u003eDevelopment Methods\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eCommand Prompt\u0026rsquo;s Joshua D. Drake posted \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://commandprompt.com/blog/thoughts-on-forks-and-open-source-licenses/\"\n  \n\u003eThoughts on Forks and Open Source Licenses\u003c/a\u003e.\u003c/p\u003e\n"
        },
        {
            "title" : "Leaving MySQL",
            "date_published" : "2021-12-05T16:41:00+02:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/software/leaving-mysql/",
            "url" : "http://blog.rockdata.net/posts/software/leaving-mysql/","authors" : [
                {
                    "name" : "Steinar Gunderson"
                }
            ],
            "content_html" : "\u003cp\u003eToday was my last day at Oracle, and thus also in the MySQL team.\u003c/p\u003e\n\u003cp\u003eWhen a decision comes to switch workplaces, there\u0026rsquo;s always the question of “why”, but that question always has multiple answers, and perhaps the simplest one is that I found another opportunity, and and as a whole, it was obvious it was time to move on when that arrived.\u003c/p\u003e\n\u003cp\u003eBut it doesn\u0026rsquo;t really explain why I did go looking for that somewhere else in the first place. The reasons for that are again complex, and it\u0026rsquo;s not possible to reduce to a single thing. But nevertheless, let me point out something that I\u0026rsquo;ve been saying both internally and externally for the last five years (although never on a stage—which explains why I\u0026rsquo;ve been staying away from stages talking about MySQL): *MySQL is a pretty poor database, and you should strongly consider using Postgres instead.*1\u003c/p\u003e\n\u003cp\u003eComing to MySQL was like stepping into a parallel universe, where there were lots of people genuinely believing that MySQL was a state-of-the-art product. At the same time, I was attending orientation and told how the optimizer worked internally, and I genuinely needed shock pauses to take in how primitive nearly everything was. It felt bizarre, but I guess you soon get used to it. In a sense, it didn\u0026rsquo;t bother me that much; lots of bad code means there\u0026rsquo;s plenty of room for opportunity for improvement, and management was strongly supportive of large refactors. More jarring were the people who insisted everything was OK (it seems most MySQL users and developers don\u0026rsquo;t really use other databases); even obviously crazy things like the executor, where everything was one big lump and everything interacted with everything else2, was hailed as “efficient” (it wasn\u0026rsquo;t).\u003c/p\u003e\n\u003cp\u003eDon\u0026rsquo;t get me wrong; I am genuinely proud of the work I have been doing, and MySQL 8.0 (with its ever-increasing minor version number) is a much better product than 5.7 was—and it will continue to improve. But there is only so much you can do; the changes others and I have been doing take the MySQL optimizer towards a fairly standard early-2000s design with some nice tweaks, but that\u0026rsquo;s also where it ends. (Someone called it “catching up, one decade at a time”, and I\u0026rsquo;m not sure if it was meant positively or negatively, but I thought a bit of it as a badge of honor.) In the end, there\u0026rsquo;s just not enough resources that I could see it turn into a competitive product, no matter how internal company communications tried to spin that Oracle is filled with geniuses and WE ARE WINNING IN THE CLOUD. And that\u0026rsquo;s probably fine (and again, not really why I quit); if you\u0026rsquo;re using MySQL and it works for you, sure, go ahead. But perhaps consider taking a look at the other side of that fence at some point, past the “OMG vacuum” memes.\u003c/p\u003e\n\u003cp\u003eMy new role will be in the Google Chrome team. It was probably about time; my T-shirt collection was getting a bit worn.\u003c/p\u003e\n\u003cp\u003e1 Don\u0026rsquo;t believe for a second that MariaDB is any better. Monty and his merry men left because they were unhappy about the new governance, not because they suddenly woke up one day and realized what a royal mess they had created in the code.\u003c/p\u003e\n\u003cp\u003e2 For instance, the sorter literally had to care whether its input came from a table scan or a range scan, because there was no modularity. Anything that wasn\u0026rsquo;t either of those two, including joins, required great contortions. Full outer joins were simply impossible to execute in the given design without rewriting the query (MySQL still doesn\u0026rsquo;t support them, but at least now it\u0026rsquo;s not hampered by the old we-can-do-left-deep-plans-only design). And don\u0026rsquo;t even get me started on the “slice” system, which is perhaps the single craziest design I\u0026rsquo;ve ever seen in any real-world software.\u003c/p\u003e\n\u003cp\u003e\u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://blog.sesse.net/blog/tech/2021-12-05-16-41_leaving_mysql.html\"\n  \n\u003eOriginal blog\u003c/a\u003e\n\u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://news.ycombinator.com/item?id=29455852\"\n  \n\u003eThe discussion at Hacker News\u003c/a\u003e\u003c/p\u003e\n"
        },
        {
            "title" : "Configuration",
            "date_published" : "2021-05-23T20:00:00+01:00",
            "date_modified" : "2022-05-24T09:25:10+08:00",
            "id" : "http://blog.rockdata.net/posts/usage/configuration/",
            "url" : "http://blog.rockdata.net/posts/usage/configuration/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003eOverview of all available server configuration options provided by the database.\u003c/p\u003e\n  \u003cdiv class=\"gblog-toc gblog-toc__level--3\"\u003e\n    \u003cnav id=\"TableOfContents\"\u003e\n  \u003cul\u003e\n    \u003cli\u003e\n      \u003cul\u003e\n        \u003cli\u003e\u003ca href=\"#configuration\"\u003eConfiguration\u003c/a\u003e\n          \u003cul\u003e\n            \u003cli\u003e\u003ca href=\"#automatic-analyzing\"\u003eAutomatic Analyzing\u003c/a\u003e\u003c/li\u003e\n            \u003cli\u003e\u003ca href=\"#run-time-statistics\"\u003eRun-time Statistics\u003c/a\u003e\u003c/li\u003e\n          \u003c/ul\u003e\n        \u003c/li\u003e\n      \u003c/ul\u003e\n    \u003c/li\u003e\n  \u003c/ul\u003e\n\u003c/nav\u003e\n    \u003chr /\u003e\n  \u003c/div\u003e\n\n\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"configuration\"\u003e\n        Configuration\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/configuration/#configuration\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Configuration\" href=\"#configuration\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch3 id=\"automatic-analyzing\"\u003e\n        Automatic Analyzing\n    \u003c/h3\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/configuration/#automatic-analyzing\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Automatic Analyzing\" href=\"#automatic-analyzing\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eThese settings control the behavior of the \u003cem\u003eautoanalyze\u003c/em\u003e feature. Refer to \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/routine-vacuuming.html#AUTOVACUUM\"\n  \n\u003eSection 24.1.6\u003c/a\u003e for more information. Note that many of these settings can be overridden on a per-table basis; see \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/sql-createtable.html#SQL-CREATETABLE-STORAGE-PARAMETERS\"\n  \n\u003eStorage Parameters\u003c/a\u003e.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eautoanalyze\u003c/code\u003e (\u003ccode\u003eboolean\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eControls whether the server should run the autoanalyze launcher daemon. This is on by default; however, \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/runtime-config-statistics.html#GUC-TRACK-COUNTS\"\n  \n\u003etrack_counts\u003c/a\u003e must also be enabled for autoanalyze to work. This parameter can only be set in the \u003ccode\u003epostgresql.conf\u003c/code\u003e file or on the server command line; however, autoanalyzing can be disabled for individual tables by changing table storage parameters.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003elog_autoanalyze_min_duration\u003c/code\u003e (\u003ccode\u003einteger\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eCauses each action executed by autoanalyze to be logged if it ran for at least the specified amount of time. Setting this to zero logs all autoanalyze actions. \u003ccode\u003e-1\u003c/code\u003e (the default) disables logging autoanalyze actions. If this value is specified without units, it is taken as milliseconds. For example, if you set this to \u003ccode\u003e250ms\u003c/code\u003e then all automatic analyzes that run 250ms or longer will be logged. In addition, when this parameter is set to any value other than \u003ccode\u003e-1\u003c/code\u003e, a message will be logged if an autoanalyze action is skipped due to a conflicting lock or a concurrently dropped relation. Enabling this parameter can be helpful in tracking autoanalyze activity. This parameter can only be set in the \u003ccode\u003epostgresql.conf\u003c/code\u003e file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eautoanalyze_max_workers\u003c/code\u003e (\u003ccode\u003einteger\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eSpecifies the maximum number of autoanalyze processes (other than the autoanalyze launcher) that may be running at any one time. The default is three. This parameter can only be set at server start.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eautoanalyze_naptime\u003c/code\u003e (\u003ccode\u003einteger\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eSpecifies the minimum delay between autoanalyze runs on any given database. In each round the daemon examines the database and issues \u003ccode\u003eANALYZE\u003c/code\u003e commands as needed for tables in that database. If this value is specified without units, it is taken as seconds. The default is one minute (\u003ccode\u003e1min\u003c/code\u003e). This parameter can only be set in the \u003ccode\u003epostgresql.conf\u003c/code\u003e file or on the server command line.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eautoanalyze_base_threshold\u003c/code\u003e (\u003ccode\u003einteger\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eSpecifies the minimum number of inserted, updated or deleted tuples needed to trigger an \u003ccode\u003eANALYZE\u003c/code\u003e in any one table. The default is 50 tuples. This parameter can only be set in the \u003ccode\u003epostgresql.conf\u003c/code\u003e file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eautoanalyze_scale_factor\u003c/code\u003e (\u003ccode\u003efloating point\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eSpecifies a fraction of the table size to add to \u003ccode\u003eautovacuum_analyze_threshold\u003c/code\u003e when deciding whether to trigger an \u003ccode\u003eANALYZE\u003c/code\u003e. The default is 0.1 (10% of table size). This parameter can only be set in the \u003ccode\u003epostgresql.conf\u003c/code\u003e file or on the server command line; but the setting can be overridden for individual tables by changing table storage parameters.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch3 id=\"run-time-statistics\"\u003e\n        Run-time Statistics\n    \u003c/h3\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/usage/configuration/#run-time-statistics\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Run-time Statistics\" href=\"#run-time-statistics\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eThese parameters control server-wide statistics collection features. When statistics collection is enabled, the data that is produced can be accessed via the \u003ccode\u003epg_stat\u003c/code\u003e and \u003ccode\u003epg_statio\u003c/code\u003e family of system views. Refer to \u003ca\n  class=\"gblog-markdown__link\"\n  href=\"https://www.postgresql.org/docs/12/monitoring.html\"\n  \n\u003eChapter 27\u003c/a\u003e for more information.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003etrack_wait_events\u003c/code\u003e (\u003ccode\u003eboolean\u003c/code\u003e)\u003c/p\u003e\n\u003cp\u003eEnables the collection of information on the wait events occured in each session, include occured times and timing information. This parameter is on by default. Note that even when enabled, this information is not visible to all users, only to superusers and the user owning the session being reported on, so it should not represent a security risk. Only superusers can change this setting.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e"
        },
        {
            "title" : "PL/scheme, Procedural Language Handler",
            "date_published" : "2021-05-23T20:00:00+01:00",
            "date_modified" : "2022-05-23T20:20:52+08:00",
            "id" : "http://blog.rockdata.net/posts/advanced/plscheme/",
            "url" : "http://blog.rockdata.net/posts/advanced/plscheme/","authors" : [
                {
                    "name" : "John Doe"
                }
            ],
            "content_html" : "\u003cp\u003ePL/scheme is a PostgreSQL procedural language handler for Scheme programming language. PL/scheme uses Chibi Scheme in the background as its Scheme interpreter. With lots of builtin SRFIs and complete R7RS compliancy of Chibi Scheme, PL/scheme can power up PostgreSQL procedures in a Lisp style.\u003c/p\u003e\n\u003cdiv class=\"gblog-post__anchorwrap flex align-center\"\u003e\n    \u003ch2 id=\"features\"\u003e\n        Features\n    \u003c/h2\u003e\n    \u003ca data-clipboard-text=\"http://blog.rockdata.net/posts/advanced/plscheme/#features\" class=\"gblog-post__anchor gblog-post__anchor--right clip\" aria-label=\"Anchor Features\" href=\"#features\"\u003e\n        \u003csvg class=\"gblog-icon gblog_link\"\u003e\u003cuse xlink:href=\"#gblog_link\"\u003e\u003c/use\u003e\u003c/svg\u003e\n    \u003c/a\u003e\n\u003c/div\u003e\n\u003cp\u003eYou can find some of the supported features by PL/scheme in the below list.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExtensible native type support even for not created yet SQL data types. Domain, complex (ie. table\u0026rsquo;s row) and pseudo (record) types are supported as well.\u003c/li\u003e\n\u003cli\u003eIN, INOUT and OUT argument mode functionality,\u003c/li\u003e\n\u003cli\u003eCaching for non-volatile (and non-SRF) procedures per [top] transaction,\u003c/li\u003e\n\u003cli\u003eand any available feature supported by Chibi Scheme (fully R7RS compliancy, module system extension, full access to POSIX system calls, networking support, multiple threads, powerful string processing, lots of builtin SRFIs and may others) are naturally shipped with PL/scheme too.\u003c/li\u003e\n\u003c/ul\u003e\n"
        }
    ]
}
